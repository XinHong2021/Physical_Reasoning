{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Baseline models\n",
        "* Regression\n",
        "* CLassification\n",
        "    * BlockStackNet4() googlenet-(64,6) - highest validation score 0.4863"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HWaiSBwEkz8V"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7vkeZCssFSz"
      },
      "source": [
        "## Baseline Models is defined\n",
        "gogglenet\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k25H8iyjtQzN"
      },
      "source": [
        "## The data set file path is defined here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vwhixF45mZlT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "'''\n",
        "In this function block, the funciton is defined to do\n",
        "1. def__init__() : get the image from the trainning data path\n",
        "2. def __len__() : get the size of hte dataset\n",
        "3. def __getitem__() : get the ralated image the correct dataset\n",
        "'''\n",
        "class BlockStackDataset(Dataset):\n",
        "  '''\n",
        "  Return the image and its label. If not access or not exist, raise error.\n",
        "  '''\n",
        "  def __init__(self, data_frame, img_dir, transform = None):\n",
        "    self.data_frame = data_frame\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "\n",
        "    if not os.path.exists(self.img_dir):\n",
        "      raise ValueError(f\"File path {self.img_dir} not exisits!\")\n",
        "    if not os.access(self.img_dir, os.R_OK):\n",
        "      raise ValueError(f\"File path {self.img_dir} is not readable!\")\n",
        "  '''\n",
        "  Return the size of the dataset\n",
        "  '''\n",
        "  def __len__(self):\n",
        "    return len(self.data_frame)\n",
        "\n",
        "  '''\n",
        "  Read the image and according to its id, get the related data in the train.csv.\n",
        "\n",
        "  Then return the corresponding image , stable_height, instability_type dataset provided.\n",
        "  '''\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = os.path.join(self.img_dir, str(self.data_frame.iloc[idx, 0])) # the first column in the train == image name\n",
        "    image = Image.open(img_name + \".jpg\")\n",
        "    label = self.data_frame.iloc[idx,4] # stable_height/instability_type\n",
        "    label = label + 1\n",
        "    instability_type = self.data_frame.iloc[idx,4] # instability_type\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, label, instability_type\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>shapeset</th>\n",
              "      <th>type</th>\n",
              "      <th>total_height</th>\n",
              "      <th>instability_type</th>\n",
              "      <th>cam_angle</th>\n",
              "      <th>stable_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>465</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>611</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
              "0   54         2     1             3                 1          1   \n",
              "1  173         1     1             4                 1          2   \n",
              "2  245         1     1             4                 1          2   \n",
              "3  465         2     1             5                 0          1   \n",
              "4  611         2     1             3                 1          1   \n",
              "\n",
              "   stable_height  \n",
              "0              2  \n",
              "1              1  \n",
              "2              1  \n",
              "3              5  \n",
              "4              1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./COMP90086_2024_Project_train/train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GACK9K_uPnV"
      },
      "source": [
        "## Trainner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xrOPfPa4t0AD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix,classification_report\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime as datatime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NfTZbRKSxh2C"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The function here helps to create the logs recording the experiment results.\n",
        "'''\n",
        "def create_log_dir():\n",
        "  current_time = datatime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  # log_dir = f'/content/drive/MyDrive/CV final project/runs/experiment_{current_time}'\n",
        "  # solution_dir = f'/content/drive/MyDrive/CV final project/trained_models/experiment_{current_time}'\n",
        "\n",
        "  log_dir = f'./runs/experiment_{current_time}'\n",
        "  solution_dir = f'./runs/experiment_{current_time}'\n",
        "  if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "  if not os.path.exists(solution_dir):\n",
        "    os.makedirs(solution_dir)\n",
        "\n",
        "  return log_dir, solution_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7ox5LZ7Aage0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define models: googlenet\n",
        "\n",
        "class TunnedBlockStackNet8(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TunnedBlockStackNet8, self).__init__()\n",
        "        # load the pre-trained model: gogglenet\n",
        "\n",
        "        self.googlenet = models.googlenet(weights = models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "        # 获取最后一层的输入特征数\n",
        "        num_ftrs = self.googlenet.fc.in_features\n",
        "        self.googlenet.fc = nn.Identity()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            # nn.Linear(num_ftrs, 256),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.50),\n",
        "            nn.Linear(num_ftrs, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.50),\n",
        "            nn.Linear(128, 3)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "      x = self.googlenet(x)\n",
        "      x = self.fc(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# thresholds = [i/100 for i in range(100)]\n",
        "# best_recall = 0\n",
        "# best_threshold = 0.5\n",
        "# for thresh in thresholds:\n",
        "#     preds = (probs[:, target_class] > thresh).long()\n",
        "#     recall = recall_score(labels == target_class, preds, zero_division=0)\n",
        "#     if recall > best_recall:\n",
        "#         best_recall = recall\n",
        "#         best_threshold = thresh\n",
        "# print(f\"最佳阈值: {best_threshold}, 召回率: {best_recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R3ipvbupjF6v"
      },
      "outputs": [],
      "source": [
        "class ClassificationBlockStackTrainer1:\n",
        "  '''\n",
        "  The function here helps to initalize the parameters used in the models and pre-process the image\n",
        "  '''\n",
        "  def __init__(self, csv_file, img_dir, model, stratify_column='stable_height', test_size=0.2,\n",
        "                 batch_size=32, num_epochs=10, learning_rate=0.001 ,random_state=42):\n",
        "        self.csv_file = csv_file\n",
        "        self.img_dir = img_dir\n",
        "        self.stratify_column = stratify_column\n",
        "        self.test_size = test_size\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = model\n",
        "\n",
        "        # load the train dataset\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "\n",
        "        # split data into train and validation dataset\n",
        "        self.train_data, self.val_data, self.train_ids, self.valid_ids = self.split_dataset()\n",
        "\n",
        "        # pre-processing the images\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "\n",
        "              #ADD MORE TRANSFORM METHODS HERE\n",
        "\n",
        "            transforms.RandomHorizontalFlip(),## ADDDED\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), ## ADDDED\n",
        "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),## ADDDED\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.train_loader = self.create_dataloader(self.train_data, self.transform)\n",
        "        self.val_loader = self.create_dataloader(self.val_data, self.transform, shuffle=False)\n",
        "\n",
        "\n",
        "        # use the gpu\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # set the loss weight\n",
        "        '''\n",
        "        Changed some thing here : to see the results\n",
        "        1. add the class_weights to each class labels with different weights,\n",
        "           more lables occurece with lower weight, few label occurence with higher weight;\n",
        "           without the weights, all the labels will be treated equally.\n",
        "\n",
        "        2. used to apply L2 regularization (also called weight decay).\n",
        "        The primary purpose of weight decay is to prevent overfitting by penalizing large weights.\n",
        "         It adds a penalty to the loss function based on the size of the weights\n",
        "         helps it generalize better to unseen data.\n",
        "         Lnew = Lold + weight_decay * sum(weight^2)\n",
        "\n",
        "        3. add scheduler to Reduces the learning rate after every step_size epochs.\n",
        "          After every 4 epochs, the learning rate will be multiplied by gamma (0.1 here), reducing it by 90%.\n",
        "        '''\n",
        "        class_weights = torch.tensor([0.5, 0.5, 2], device= self.device)\n",
        "        # class_weights = torch.tensor([100/25 , 100/25, 100/20,  100/15, 100/10,  100/5], device= self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss(weight=class_weights) # CrossEntropy for multi categorical-label predication\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate , weight_decay=0.0001)\n",
        "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size = 15, gamma=0.1)\n",
        "\n",
        "\n",
        "  '''\n",
        "  The function helps to split the data set into the training and validation dataset according to the\n",
        "  size pre-determined.\n",
        "  '''\n",
        "\n",
        "  def split_dataset(self):\n",
        "    split = StratifiedShuffleSplit(n_splits=1, test_size=self.test_size, random_state=42)\n",
        "    train_ids = []\n",
        "    valid_ids = []\n",
        "    for train_idx, val_idx in split.split(self.data_frame, self.data_frame[self.stratify_column]):\n",
        "      train_data = self.data_frame.iloc[train_idx]\n",
        "      val_data = self.data_frame.iloc[val_idx]\n",
        "      train_ids.append(train_idx)\n",
        "      valid_ids.append(val_idx)\n",
        "    print(f\"Train dataset size: {len(train_data)}\",\n",
        "       f\"Validation dataset size: {len(val_data)}\",\n",
        "       f\"length of train_ids{(len(train_ids))}\",\n",
        "       f\"length of valid_ids{(len(valid_ids))}\")\n",
        "    return train_data, val_data, train_ids, valid_ids\n",
        "\n",
        "\n",
        "  '''\n",
        "  The function helps to loda the image\n",
        "  '''\n",
        "  def create_dataloader(self, data_frame, transform, shuffle=True):\n",
        "    dataset = BlockStackDataset(data_frame, self.img_dir, transform=transform) # transform 可以用来数据增强\n",
        "    return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
        "\n",
        "\n",
        "  def generate_classification_report(self, outputs, labels):\n",
        "    predicted = outputs # 'outputs' is already a numpy array after prediction\n",
        "    labels = labels\n",
        "    print(classification_report(labels, predicted, zero_division=0))\n",
        "\n",
        "\n",
        "\n",
        "  def calculate_confusion_matrix(self, outputs, labels):\n",
        "    predicted = outputs\n",
        "    labels = labels\n",
        "    matrix = confusion_matrix(labels, predicted)\n",
        "    print(matrix)\n",
        "\n",
        "  def calculate_class3_recall(self, outputs, labels):\n",
        "    recall_all_class = recall_score(labels, outputs, average=None)\n",
        "    recall_class3 = recall_all_class[2]\n",
        "    return recall_class3\n",
        "\n",
        "  def validate(self):\n",
        "    self.model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []  # add all the lables\n",
        "    all_predictions = []  # add all the prediction\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _ in self.val_loader:\n",
        "            inputs, labels = inputs.to(self.device), labels.to(self.device).long()\n",
        "            labels = labels - 1\n",
        "            outputs = self.model(inputs)\n",
        "            predicted = torch.argmax(outputs, 1)\n",
        "\n",
        "            # collecting all the lables and predictions\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # calculate the loss\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # calculate the correct predication\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    # calculate the accuracy rate\n",
        "    val_accuracy = correct_predictions / total_samples\n",
        "    self.generate_classification_report(np.array(all_predictions), np.array(all_labels))\n",
        "    self.calculate_confusion_matrix(np.array(all_predictions), np.array(all_labels))\n",
        "    recall_class3 = self.calculate_class3_recall(np.array(all_predictions), np.array(all_labels))\n",
        "    return val_loss/len(self.val_loader),val_accuracy, all_labels, all_predictions, recall_class3\n",
        "\n",
        "\n",
        "\n",
        "  '''\n",
        "  The function here is used as the main training function on the image by using the pre-definned models in\n",
        "  hte first model class.\n",
        "  '''\n",
        "\n",
        "  def train(self):\n",
        "      _, solution_dir = create_log_dir()\n",
        "\n",
        "      best_class3_recall = 0.0\n",
        "      for epoch in range(self.num_epochs):\n",
        "          self.model.train()\n",
        "          running_loss = 0.0\n",
        "          running_accuracy = 0.0\n",
        "\n",
        "          # monitor the process\n",
        "          with tqdm(self.train_loader, unit=\"batch\") as tepoch:\n",
        "              tepoch.set_description(f\"Epoch {epoch + 1}/{self.num_epochs}\")\n",
        "\n",
        "              for inputs, labels, _ in tepoch:\n",
        "                  inputs, labels = inputs.to(self.device), labels.to(self.device).long()\n",
        "                  labels = labels - 1\n",
        "\n",
        "                  #forward propagation\n",
        "                  self.optimizer.zero_grad()\n",
        "                  raw_outputs = self.model(inputs)\n",
        "                  loss = self.criterion(raw_outputs, labels)  # loss calculation\n",
        "\n",
        "                  loss.backward()  # backward propagation\n",
        "                  self.optimizer.step()\n",
        "\n",
        "                  #Loss calculating\n",
        "                  running_loss += loss.item()\n",
        "                  _, predicted = torch.max(raw_outputs, 1)\n",
        "                  accuracy = (predicted == labels).sum().item()/ labels.size(0)\n",
        "                  running_accuracy += accuracy\n",
        "                  tepoch.set_postfix(loss=running_loss / len(self.train_loader),\n",
        "                            accuracy=running_accuracy / len(self.train_loader))\n",
        "\n",
        "\n",
        "\n",
        "          self.scheduler.step()\n",
        "          print(self.scheduler.get_last_lr())\n",
        "\n",
        "\n",
        "          val_loss,val_accuracy, all_labels, all_predictions, class3_recall = self.validate()\n",
        "\n",
        "          print(f\"Epoch {epoch + 1}/{self.num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "          # if val_accuracy > best_val_accuracy:\n",
        "          #     best_val_accuracy = val_accuracy\n",
        "          #     torch.save(self.model.state_dict(), f'{solution_dir}/best_model.pth')\n",
        "          #     print('Best model saved!')\n",
        "          if class3_recall > best_class3_recall:\n",
        "              best_class3_recall = class3_recall\n",
        "              torch.save(self.model.state_dict(), f'{solution_dir}/best_model.pth')\n",
        "              print('Best model saved!')\n",
        "      print('Finished Training')\n",
        "      print(f'Best validation recall: {best_class3_recall:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 2\n",
        "* 2 Linear layer, drop out rate = 0.5, class weight [0.5, 0.5, 2]\n",
        "* Save best recall model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 6144 Validation dataset size: 1536 length of train_ids1 length of valid_ids1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/16: 100%|██████████| 192/192 [06:36<00:00,  2.06s/batch, accuracy=0.653, loss=0.77]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.01      0.01       369\n",
            "           1       0.67      0.89      0.76       777\n",
            "           2       0.73      0.92      0.81       390\n",
            "\n",
            "    accuracy                           0.69      1536\n",
            "   macro avg       0.56      0.61      0.53      1536\n",
            "weighted avg       0.59      0.69      0.60      1536\n",
            "\n",
            "[[  2 315  52]\n",
            " [  4 694  79]\n",
            " [  1  31 358]]\n",
            "Epoch 1/16, Validation Loss: 0.6630, Validation Accuracy: 0.6862\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/16: 100%|██████████| 192/192 [06:32<00:00,  2.05s/batch, accuracy=0.696, loss=0.653]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.00      0.01       369\n",
            "           1       0.66      0.90      0.76       777\n",
            "           2       0.76      0.92      0.83       390\n",
            "\n",
            "    accuracy                           0.69      1536\n",
            "   macro avg       0.58      0.61      0.53      1536\n",
            "weighted avg       0.61      0.69      0.60      1536\n",
            "\n",
            "[[  1 328  40]\n",
            " [  2 699  76]\n",
            " [  0  31 359]]\n",
            "Epoch 2/16, Validation Loss: 0.6764, Validation Accuracy: 0.6895\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/16: 100%|██████████| 192/192 [06:32<00:00,  2.05s/batch, accuracy=0.714, loss=0.608]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.38      0.44       369\n",
            "           1       0.71      0.84      0.77       777\n",
            "           2       0.95      0.86      0.90       390\n",
            "\n",
            "    accuracy                           0.73      1536\n",
            "   macro avg       0.73      0.69      0.70      1536\n",
            "weighted avg       0.73      0.73      0.72      1536\n",
            "\n",
            "[[139 221   9]\n",
            " [118 651   8]\n",
            " [ 12  43 335]]\n",
            "Epoch 3/16, Validation Loss: 0.5695, Validation Accuracy: 0.7324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/16: 100%|██████████| 192/192 [06:32<00:00,  2.04s/batch, accuracy=0.718, loss=0.595]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.53      0.49       369\n",
            "           1       0.72      0.73      0.72       777\n",
            "           2       0.97      0.78      0.87       390\n",
            "\n",
            "    accuracy                           0.70      1536\n",
            "   macro avg       0.71      0.68      0.69      1536\n",
            "weighted avg       0.72      0.70      0.70      1536\n",
            "\n",
            "[[195 170   4]\n",
            " [204 568   5]\n",
            " [ 30  54 306]]\n",
            "Epoch 4/16, Validation Loss: 0.6560, Validation Accuracy: 0.6960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/16: 100%|██████████| 192/192 [06:33<00:00,  2.05s/batch, accuracy=0.725, loss=0.588]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.24      0.33       369\n",
            "           1       0.70      0.85      0.77       777\n",
            "           2       0.88      0.96      0.92       390\n",
            "\n",
            "    accuracy                           0.73      1536\n",
            "   macro avg       0.70      0.68      0.67      1536\n",
            "weighted avg       0.70      0.73      0.70      1536\n",
            "\n",
            "[[ 90 264  15]\n",
            " [ 81 661  35]\n",
            " [  4  13 373]]\n",
            "Epoch 5/16, Validation Loss: 0.5420, Validation Accuracy: 0.7318\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/16: 100%|██████████| 192/192 [06:29<00:00,  2.03s/batch, accuracy=0.741, loss=0.56]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.05      0.10       369\n",
            "           1       0.67      0.98      0.79       777\n",
            "           2       0.95      0.89      0.92       390\n",
            "\n",
            "    accuracy                           0.74      1536\n",
            "   macro avg       0.79      0.64      0.60      1536\n",
            "weighted avg       0.76      0.74      0.66      1536\n",
            "\n",
            "[[ 19 344   6]\n",
            " [  3 762  12]\n",
            " [  3  38 349]]\n",
            "Epoch 6/16, Validation Loss: 0.5835, Validation Accuracy: 0.7357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/16: 100%|██████████| 192/192 [06:30<00:00,  2.03s/batch, accuracy=0.739, loss=0.559]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.64      0.56       369\n",
            "           1       0.79      0.71      0.75       777\n",
            "           2       0.96      0.89      0.92       390\n",
            "\n",
            "    accuracy                           0.74      1536\n",
            "   macro avg       0.75      0.75      0.74      1536\n",
            "weighted avg       0.76      0.74      0.75      1536\n",
            "\n",
            "[[236 128   5]\n",
            " [216 550  11]\n",
            " [ 26  16 348]]\n",
            "Epoch 7/16, Validation Loss: 0.5552, Validation Accuracy: 0.7383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/16: 100%|██████████| 192/192 [06:30<00:00,  2.03s/batch, accuracy=0.745, loss=0.563]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.18      0.28       369\n",
            "           1       0.71      0.87      0.78       777\n",
            "           2       0.78      0.95      0.86       390\n",
            "\n",
            "    accuracy                           0.72      1536\n",
            "   macro avg       0.70      0.67      0.64      1536\n",
            "weighted avg       0.71      0.72      0.68      1536\n",
            "\n",
            "[[ 67 258  44]\n",
            " [ 40 677  60]\n",
            " [  1  20 369]]\n",
            "Epoch 8/16, Validation Loss: 0.6433, Validation Accuracy: 0.7246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/16: 100%|██████████| 192/192 [06:30<00:00,  2.03s/batch, accuracy=0.754, loss=0.552]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.08      0.15       369\n",
            "           1       0.65      0.98      0.78       777\n",
            "           2       0.99      0.81      0.89       390\n",
            "\n",
            "    accuracy                           0.72      1536\n",
            "   macro avg       0.76      0.63      0.61      1536\n",
            "weighted avg       0.74      0.72      0.66      1536\n",
            "\n",
            "[[ 31 337   1]\n",
            " [ 13 763   1]\n",
            " [  4  69 317]]\n",
            "Epoch 9/16, Validation Loss: 0.6983, Validation Accuracy: 0.7233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/16: 100%|██████████| 192/192 [06:30<00:00,  2.03s/batch, accuracy=0.746, loss=0.537]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.30      0.42       369\n",
            "           1       0.72      0.92      0.81       777\n",
            "           2       0.94      0.92      0.93       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.78      0.71      0.72      1536\n",
            "weighted avg       0.77      0.77      0.75      1536\n",
            "\n",
            "[[112 247  10]\n",
            " [ 52 714  11]\n",
            " [  3  29 358]]\n",
            "Epoch 10/16, Validation Loss: 0.5184, Validation Accuracy: 0.7708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/16: 100%|██████████| 192/192 [06:29<00:00,  2.03s/batch, accuracy=0.757, loss=0.537]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.49      0.53       369\n",
            "           1       0.73      0.84      0.78       777\n",
            "           2       0.99      0.82      0.90       390\n",
            "\n",
            "    accuracy                           0.75      1536\n",
            "   macro avg       0.76      0.72      0.74      1536\n",
            "weighted avg       0.76      0.75      0.75      1536\n",
            "\n",
            "[[180 187   2]\n",
            " [120 655   2]\n",
            " [ 16  53 321]]\n",
            "Epoch 11/16, Validation Loss: 0.5791, Validation Accuracy: 0.7526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/16: 100%|██████████| 192/192 [06:34<00:00,  2.05s/batch, accuracy=0.759, loss=0.531]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.58      0.57       369\n",
            "           1       0.78      0.79      0.79       777\n",
            "           2       0.97      0.90      0.93       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.77      0.76      0.76      1536\n",
            "weighted avg       0.78      0.77      0.77      1536\n",
            "\n",
            "[[215 148   6]\n",
            " [155 616   6]\n",
            " [ 16  22 352]]\n",
            "Epoch 12/16, Validation Loss: 0.5306, Validation Accuracy: 0.7702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/16: 100%|██████████| 192/192 [06:34<00:00,  2.06s/batch, accuracy=0.749, loss=0.557]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.33      0.43       369\n",
            "           1       0.72      0.89      0.80       777\n",
            "           2       0.93      0.91      0.92       390\n",
            "\n",
            "    accuracy                           0.76      1536\n",
            "   macro avg       0.76      0.71      0.71      1536\n",
            "weighted avg       0.75      0.76      0.74      1536\n",
            "\n",
            "[[120 239  10]\n",
            " [ 65 694  18]\n",
            " [  6  30 354]]\n",
            "Epoch 13/16, Validation Loss: 0.5233, Validation Accuracy: 0.7604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/16: 100%|██████████| 192/192 [06:35<00:00,  2.06s/batch, accuracy=0.756, loss=0.534]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.59      0.57       369\n",
            "           1       0.78      0.75      0.76       777\n",
            "           2       0.93      0.93      0.93       390\n",
            "\n",
            "    accuracy                           0.76      1536\n",
            "   macro avg       0.75      0.76      0.75      1536\n",
            "weighted avg       0.76      0.76      0.76      1536\n",
            "\n",
            "[[217 144   8]\n",
            " [172 584  21]\n",
            " [  6  22 362]]\n",
            "Epoch 14/16, Validation Loss: 0.5162, Validation Accuracy: 0.7572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/16: 100%|██████████| 192/192 [06:36<00:00,  2.07s/batch, accuracy=0.762, loss=0.518]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.46      0.52       369\n",
            "           1       0.76      0.84      0.80       777\n",
            "           2       0.92      0.94      0.93       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.76      0.75      0.75      1536\n",
            "weighted avg       0.77      0.77      0.77      1536\n",
            "\n",
            "[[170 184  15]\n",
            " [107 654  16]\n",
            " [  3  21 366]]\n",
            "Epoch 15/16, Validation Loss: 0.5210, Validation Accuracy: 0.7747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/16: 100%|██████████| 192/192 [06:42<00:00,  2.10s/batch, accuracy=0.785, loss=0.481]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.37      0.46       369\n",
            "           1       0.73      0.89      0.80       777\n",
            "           2       0.98      0.91      0.95       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.78      0.73      0.74      1536\n",
            "weighted avg       0.77      0.77      0.76      1536\n",
            "\n",
            "[[138 227   4]\n",
            " [ 81 694   2]\n",
            " [  7  27 356]]\n",
            "Epoch 16/16, Validation Loss: 0.4927, Validation Accuracy: 0.7734\n",
            "Finished Training\n",
            "Best validation recall: 0.9564\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "if __name__ == \"__main__\":\n",
        "    model = TunnedBlockStackNet8()\n",
        "    trainer = ClassificationBlockStackTrainer1(\n",
        "        csv_file = './COMP90086_2024_Project_train/train.csv', ##\n",
        "        img_dir='./COMP90086_2024_Project_train/train', ##\n",
        "        model=model,\n",
        "        test_size=0.2, \n",
        "        num_epochs=16,\n",
        "        batch_size=32\n",
        "        )\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 1\n",
        "* 2 Linear layer, drop out rate = 0.5, class weight [20, 10, 5]\n",
        "* Best model: \n",
        "Epoch 16/16: 100%|██████████| 48/48 [06:34<00:00,  8.22s/batch, accuracy=0.815, loss=0.424] \n",
        "[0.0001]\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.68      0.43      0.52       369\n",
        "           1       0.75      0.90      0.82       777\n",
        "           2       0.96      0.93      0.95       390\n",
        "\n",
        "    accuracy                           0.79      1536\n",
        "   macro avg       0.80      0.75      0.76      1536\n",
        "weighted avg       0.79      0.79      0.78      1536\n",
        "\n",
        "[[157 206   6]\n",
        " [ 71 698   8]\n",
        " [  3  25 362]]\n",
        "Epoch 16/16, Validation Loss: 0.4660, Validation Accuracy: 0.7923\n",
        "Best model saved!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 6144 Validation dataset size: 1536 length of train_ids1 length of valid_ids1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/16: 100%|██████████| 48/48 [06:29<00:00,  8.11s/batch, accuracy=0.638, loss=0.764]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.09      0.15       369\n",
            "           1       0.64      0.97      0.77       777\n",
            "           2       0.96      0.75      0.84       390\n",
            "\n",
            "    accuracy                           0.70      1536\n",
            "   macro avg       0.76      0.60      0.59      1536\n",
            "weighted avg       0.73      0.70      0.64      1536\n",
            "\n",
            "[[ 32 336   1]\n",
            " [ 13 754  10]\n",
            " [  2  95 293]]\n",
            "Epoch 1/16, Validation Loss: 0.6508, Validation Accuracy: 0.7025\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/16: 100%|██████████| 48/48 [06:26<00:00,  8.06s/batch, accuracy=0.721, loss=0.589] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.24      0.35       369\n",
            "           1       0.71      0.89      0.79       777\n",
            "           2       0.84      0.90      0.87       390\n",
            "\n",
            "    accuracy                           0.73      1536\n",
            "   macro avg       0.72      0.68      0.67      1536\n",
            "weighted avg       0.72      0.73      0.70      1536\n",
            "\n",
            "[[ 89 254  26]\n",
            " [ 48 688  41]\n",
            " [  6  33 351]]\n",
            "Epoch 2/16, Validation Loss: 0.5953, Validation Accuracy: 0.7344\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/16: 100%|██████████| 48/48 [06:27<00:00,  8.08s/batch, accuracy=0.738, loss=0.557] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.27      0.38       369\n",
            "           1       0.71      0.90      0.80       777\n",
            "           2       0.90      0.92      0.91       390\n",
            "\n",
            "    accuracy                           0.76      1536\n",
            "   macro avg       0.76      0.70      0.70      1536\n",
            "weighted avg       0.75      0.76      0.73      1536\n",
            "\n",
            "[[100 255  14]\n",
            " [ 50 702  25]\n",
            " [  3  27 360]]\n",
            "Epoch 3/16, Validation Loss: 0.5303, Validation Accuracy: 0.7565\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/16: 100%|██████████| 48/48 [06:42<00:00,  8.40s/batch, accuracy=0.747, loss=0.543] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.11      0.19       369\n",
            "           1       0.69      0.96      0.80       777\n",
            "           2       0.92      0.93      0.93       390\n",
            "\n",
            "    accuracy                           0.75      1536\n",
            "   macro avg       0.79      0.67      0.64      1536\n",
            "weighted avg       0.76      0.75      0.69      1536\n",
            "\n",
            "[[ 41 317  11]\n",
            " [ 12 746  19]\n",
            " [  1  25 364]]\n",
            "Epoch 4/16, Validation Loss: 0.5258, Validation Accuracy: 0.7493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/16: 100%|██████████| 48/48 [06:22<00:00,  7.97s/batch, accuracy=0.764, loss=0.518] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.50      0.53       369\n",
            "           1       0.75      0.82      0.78       777\n",
            "           2       0.97      0.89      0.93       390\n",
            "\n",
            "    accuracy                           0.76      1536\n",
            "   macro avg       0.76      0.74      0.75      1536\n",
            "weighted avg       0.76      0.76      0.76      1536\n",
            "\n",
            "[[186 179   4]\n",
            " [137 635   5]\n",
            " [ 11  33 346]]\n",
            "Epoch 5/16, Validation Loss: 0.5372, Validation Accuracy: 0.7598\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/16: 100%|██████████| 48/48 [06:26<00:00,  8.05s/batch, accuracy=0.767, loss=0.513] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.15      0.24       369\n",
            "           1       0.67      0.98      0.79       777\n",
            "           2       0.99      0.82      0.90       390\n",
            "\n",
            "    accuracy                           0.74      1536\n",
            "   macro avg       0.80      0.65      0.64      1536\n",
            "weighted avg       0.76      0.74      0.69      1536\n",
            "\n",
            "[[ 54 313   2]\n",
            " [ 16 760   1]\n",
            " [  4  67 319]]\n",
            "Epoch 6/16, Validation Loss: 0.6022, Validation Accuracy: 0.7376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/16: 100%|██████████| 48/48 [06:29<00:00,  8.11s/batch, accuracy=0.764, loss=0.518]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.21      0.33       369\n",
            "           1       0.67      0.97      0.79       777\n",
            "           2       1.00      0.81      0.89       390\n",
            "\n",
            "    accuracy                           0.74      1536\n",
            "   macro avg       0.80      0.66      0.67      1536\n",
            "weighted avg       0.77      0.74      0.71      1536\n",
            "\n",
            "[[ 79 290   0]\n",
            " [ 27 750   0]\n",
            " [  1  74 315]]\n",
            "Epoch 7/16, Validation Loss: 0.5824, Validation Accuracy: 0.7448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/16: 100%|██████████| 48/48 [06:25<00:00,  8.02s/batch, accuracy=0.779, loss=0.5]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.51      0.55       369\n",
            "           1       0.76      0.82      0.79       777\n",
            "           2       0.95      0.92      0.94       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.77      0.75      0.76      1536\n",
            "weighted avg       0.77      0.77      0.77      1536\n",
            "\n",
            "[[190 173   6]\n",
            " [131 635  11]\n",
            " [  6  25 359]]\n",
            "Epoch 8/16, Validation Loss: 0.5117, Validation Accuracy: 0.7708\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/16: 100%|██████████| 48/48 [06:18<00:00,  7.88s/batch, accuracy=0.775, loss=0.487]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.25      0.37       369\n",
            "           1       0.69      0.95      0.80       777\n",
            "           2       0.99      0.85      0.92       390\n",
            "\n",
            "    accuracy                           0.76      1536\n",
            "   macro avg       0.79      0.68      0.70      1536\n",
            "weighted avg       0.77      0.76      0.73      1536\n",
            "\n",
            "[[ 93 273   3]\n",
            " [ 38 739   0]\n",
            " [  4  54 332]]\n",
            "Epoch 9/16, Validation Loss: 0.5346, Validation Accuracy: 0.7578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/16: 100%|██████████| 48/48 [06:13<00:00,  7.78s/batch, accuracy=0.781, loss=0.48]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.08      0.14       369\n",
            "           1       0.66      0.99      0.79       777\n",
            "           2       0.99      0.86      0.92       390\n",
            "\n",
            "    accuracy                           0.74      1536\n",
            "   macro avg       0.83      0.64      0.62      1536\n",
            "weighted avg       0.78      0.74      0.67      1536\n",
            "\n",
            "[[ 29 339   1]\n",
            " [  6 768   3]\n",
            " [  0  53 337]]\n",
            "Epoch 10/16, Validation Loss: 0.5542, Validation Accuracy: 0.7383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/16: 100%|██████████| 48/48 [06:14<00:00,  7.81s/batch, accuracy=0.784, loss=0.484]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.25      0.37       369\n",
            "           1       0.70      0.95      0.81       777\n",
            "           2       0.98      0.89      0.94       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.80      0.70      0.71      1536\n",
            "weighted avg       0.78      0.77      0.74      1536\n",
            "\n",
            "[[ 93 273   3]\n",
            " [ 32 742   3]\n",
            " [  3  39 348]]\n",
            "Epoch 11/16, Validation Loss: 0.5306, Validation Accuracy: 0.7702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/16: 100%|██████████| 48/48 [06:22<00:00,  7.98s/batch, accuracy=0.783, loss=0.476] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.39      0.48       369\n",
            "           1       0.73      0.91      0.81       777\n",
            "           2       0.98      0.86      0.91       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.78      0.72      0.73      1536\n",
            "weighted avg       0.77      0.77      0.76      1536\n",
            "\n",
            "[[143 223   3]\n",
            " [ 68 704   5]\n",
            " [ 12  44 334]]\n",
            "Epoch 12/16, Validation Loss: 0.5569, Validation Accuracy: 0.7689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/16: 100%|██████████| 48/48 [06:35<00:00,  8.23s/batch, accuracy=0.788, loss=0.471]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.56      0.54       369\n",
            "           1       0.75      0.76      0.76       777\n",
            "           2       0.99      0.86      0.92       390\n",
            "\n",
            "    accuracy                           0.74      1536\n",
            "   macro avg       0.75      0.73      0.74      1536\n",
            "weighted avg       0.75      0.74      0.74      1536\n",
            "\n",
            "[[208 159   2]\n",
            " [182 593   2]\n",
            " [ 15  40 335]]\n",
            "Epoch 13/16, Validation Loss: 0.5373, Validation Accuracy: 0.7396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/16: 100%|██████████| 48/48 [06:39<00:00,  8.32s/batch, accuracy=0.803, loss=0.447] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.51      0.55       369\n",
            "           1       0.77      0.83      0.80       777\n",
            "           2       0.95      0.94      0.94       390\n",
            "\n",
            "    accuracy                           0.78      1536\n",
            "   macro avg       0.77      0.76      0.77      1536\n",
            "weighted avg       0.78      0.78      0.78      1536\n",
            "\n",
            "[[189 172   8]\n",
            " [121 645  11]\n",
            " [  7  17 366]]\n",
            "Epoch 14/16, Validation Loss: 0.5166, Validation Accuracy: 0.7812\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/16: 100%|██████████| 48/48 [06:51<00:00,  8.57s/batch, accuracy=0.796, loss=0.462]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.28      0.40       369\n",
            "           1       0.71      0.94      0.81       777\n",
            "           2       0.97      0.89      0.93       390\n",
            "\n",
            "    accuracy                           0.77      1536\n",
            "   macro avg       0.79      0.70      0.71      1536\n",
            "weighted avg       0.77      0.77      0.74      1536\n",
            "\n",
            "[[104 262   3]\n",
            " [ 42 729   6]\n",
            " [  3  41 346]]\n",
            "Epoch 15/16, Validation Loss: 0.5241, Validation Accuracy: 0.7676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/16: 100%|██████████| 48/48 [06:34<00:00,  8.22s/batch, accuracy=0.815, loss=0.424] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.43      0.52       369\n",
            "           1       0.75      0.90      0.82       777\n",
            "           2       0.96      0.93      0.95       390\n",
            "\n",
            "    accuracy                           0.79      1536\n",
            "   macro avg       0.80      0.75      0.76      1536\n",
            "weighted avg       0.79      0.79      0.78      1536\n",
            "\n",
            "[[157 206   6]\n",
            " [ 71 698   8]\n",
            " [  3  25 362]]\n",
            "Epoch 16/16, Validation Loss: 0.4660, Validation Accuracy: 0.7923\n",
            "Best model saved!\n",
            "Finished Training\n",
            "Best validation accuracy: 0.7923\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "if __name__ == \"__main__\":\n",
        "    model = TunnedBlockStackNet8()\n",
        "    trainer = ClassificationBlockStackTrainer1(\n",
        "        csv_file = './COMP90086_2024_Project_train/train.csv', ##\n",
        "        img_dir='./COMP90086_2024_Project_train/train', ##\n",
        "        model=model,\n",
        "        test_size=0.2, # used to control the size of data in split_dataset(self)\n",
        "        num_epochs=16,\n",
        "        batch_size=128\n",
        "        )\n",
        "    trainer.train()\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ids = trainer.train_ids\n",
        "valid_ids = trainer.valid_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'valid_ids' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(valid_ids[\u001b[38;5;241m0\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_ids' is not defined"
          ]
        }
      ],
      "source": [
        "len(valid_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.70      0.72       384\n",
            "           1       0.70      0.70      0.70       384\n",
            "           2       0.61      0.68      0.64       307\n",
            "           3       0.58      0.62      0.60       230\n",
            "           4       0.53      0.49      0.51       154\n",
            "           5       0.43      0.35      0.39        77\n",
            "\n",
            "    accuracy                           0.64      1536\n",
            "   macro avg       0.60      0.59      0.59      1536\n",
            "weighted avg       0.64      0.64      0.64      1536\n",
            "\n",
            "[[267  41  32  26  11   7]\n",
            " [ 34 269  38  27  12   4]\n",
            " [ 20  35 209  23  12   8]\n",
            " [ 19  13  31 143  18   6]\n",
            " [ 14  10  20  24  75  11]\n",
            " [  7  14  13   3  13  27]]\n"
          ]
        }
      ],
      "source": [
        "val_loss,val_accuracy, all_labels, all_predictions = trainer.validate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.64453125"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison = map(lambda all_labels, all_predictions: all_labels == all_predictions, all_labels, all_predictions)\n",
        "sum(comparison)/len(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>shapeset</th>\n",
              "      <th>type</th>\n",
              "      <th>total_height</th>\n",
              "      <th>instability_type</th>\n",
              "      <th>cam_angle</th>\n",
              "      <th>stable_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7334</th>\n",
              "      <td>956915</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3955</th>\n",
              "      <td>516709</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>77447</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>212770</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5645</th>\n",
              "      <td>745098</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
              "7334  956915         2     2             4                 2          1   \n",
              "3955  516709         1     2             5                 1          1   \n",
              "619    77447         1     2             5                 1          1   \n",
              "1594  212770         2     2             4                 2          1   \n",
              "5645  745098         2     2             6                 1          1   \n",
              "\n",
              "      stable_height  \n",
              "7334              1  \n",
              "3955              3  \n",
              "619               3  \n",
              "1594              1  \n",
              "5645              4  "
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data = trainer.val_data\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_39098/1482792748.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['predicted'] = [pred+1 for pred in all_predictions]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>shapeset</th>\n",
              "      <th>type</th>\n",
              "      <th>total_height</th>\n",
              "      <th>instability_type</th>\n",
              "      <th>cam_angle</th>\n",
              "      <th>stable_height</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7334</th>\n",
              "      <td>956915</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3955</th>\n",
              "      <td>516709</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>77447</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>212770</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5645</th>\n",
              "      <td>745098</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
              "7334  956915         2     2             4                 2          1   \n",
              "3955  516709         1     2             5                 1          1   \n",
              "619    77447         1     2             5                 1          1   \n",
              "1594  212770         2     2             4                 2          1   \n",
              "5645  745098         2     2             6                 1          1   \n",
              "\n",
              "      stable_height  predicted  \n",
              "7334              1          1  \n",
              "3955              3          2  \n",
              "619               3          3  \n",
              "1594              1          1  \n",
              "5645              4          2  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data['predicted'] = [pred+1 for pred in all_predictions]\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_39098/2673748297.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_data['pred_type'] = val_data['predicted'] == val_data['stable_height']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>shapeset</th>\n",
              "      <th>type</th>\n",
              "      <th>total_height</th>\n",
              "      <th>instability_type</th>\n",
              "      <th>cam_angle</th>\n",
              "      <th>stable_height</th>\n",
              "      <th>predicted</th>\n",
              "      <th>pred_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7334</th>\n",
              "      <td>956915</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3955</th>\n",
              "      <td>516709</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>77447</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>212770</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5645</th>\n",
              "      <td>745098</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
              "7334  956915         2     2             4                 2          1   \n",
              "3955  516709         1     2             5                 1          1   \n",
              "619    77447         1     2             5                 1          1   \n",
              "1594  212770         2     2             4                 2          1   \n",
              "5645  745098         2     2             6                 1          1   \n",
              "\n",
              "      stable_height  predicted  pred_type  \n",
              "7334              1          1       True  \n",
              "3955              3          2      False  \n",
              "619               3          3       True  \n",
              "1594              1          1       True  \n",
              "5645              4          2      False  "
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data['pred_type'] = val_data['predicted'] == val_data['stable_height']\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.64453125"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_data[val_data['predicted']== val_data['stable_height']])/len(valid_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.64453125"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data['pred_type'].sum()/len(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "instability_type\n",
              "0    369\n",
              "1    777\n",
              "2    390\n",
              "Name: pred_type, dtype: int64"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data.groupby('instability_type').pred_type.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "shapeset\n",
              "1    0.616105\n",
              "2    0.659681\n",
              "Name: pred_type, dtype: float64"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data.groupby('shapeset').pred_type.sum()/val_data.groupby('shapeset').pred_type.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "type\n",
              "1    0.768021\n",
              "2    0.522639\n",
              "Name: pred_type, dtype: float64"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data.groupby('type').pred_type.sum()/val_data.groupby('type').pred_type.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "instability_type\n",
              "0    0.544715\n",
              "1    0.550837\n",
              "2    0.925641\n",
              "Name: pred_type, dtype: float64"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data.groupby('instability_type').pred_type.sum()/val_data.groupby('instability_type').pred_type.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>shapeset</th>\n",
              "      <th>type</th>\n",
              "      <th>total_height</th>\n",
              "      <th>instability_type</th>\n",
              "      <th>cam_angle</th>\n",
              "      <th>stable_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>465</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>611</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
              "0   54         2     1             3                 1          1   \n",
              "1  173         1     1             4                 1          2   \n",
              "2  245         1     1             4                 1          2   \n",
              "3  465         2     1             5                 0          1   \n",
              "4  611         2     1             3                 1          1   \n",
              "\n",
              "   stable_height  \n",
              "0              2  \n",
              "1              1  \n",
              "2              1  \n",
              "3              5  \n",
              "4              1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./COMP90086_2024_Project_train/train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>shapeset</th>\n",
              "      <th>type</th>\n",
              "      <th>total_height</th>\n",
              "      <th>cam_angle</th>\n",
              "      <th>stable_height</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>instability_type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3840</td>\n",
              "      <td>3840</td>\n",
              "      <td>3840</td>\n",
              "      <td>3840</td>\n",
              "      <td>3840</td>\n",
              "      <td>3840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  shapeset  type  total_height  cam_angle  stable_height\n",
              "instability_type                                                              \n",
              "0                 1920      1920  1920          1920       1920           1920\n",
              "1                 3840      3840  3840          3840       3840           3840\n",
              "2                 1920      1920  1920          1920       1920           1920"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby('instability_type').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_67928/1284981419.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model = torch.load('./runs/experiment_20241012-010838/best_model.pth')\n"
          ]
        }
      ],
      "source": [
        "best_model = torch.load('./runs/experiment_20241012-010838/best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_67928/1886415100.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model = torch.load('./runs/experiment_20241012-010838/best_model.pth',map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs/experiment_20241012-010838/best_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m best_model\u001b[38;5;241m.\u001b[39meval()\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
          ]
        }
      ],
      "source": [
        "best_model = torch.load('./runs/experiment_20241012-010838/best_model.pth',map_location=torch.device('cpu'))\n",
        "best_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Model\n",
        "\n",
        "Net8, epoch = 8, no batch_size defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q39AMlmH_3fn",
        "outputId": "f009ffad-9b8d-4a78-eaa4-cb942caa4ba2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /Users/macbookpro/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:03<00:00, 14.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 6144 Validation dataset size: 1536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/8: 100%|██████████| 192/192 [06:38<00:00,  2.07s/batch, accuracy=0.274, loss=1.58]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.42      0.45       384\n",
            "           1       0.38      0.45      0.41       384\n",
            "           2       0.30      0.62      0.41       307\n",
            "           3       0.25      0.06      0.09       230\n",
            "           4       0.26      0.12      0.16       154\n",
            "           5       0.00      0.00      0.00        77\n",
            "\n",
            "    accuracy                           0.36      1536\n",
            "   macro avg       0.28      0.28      0.25      1536\n",
            "weighted avg       0.34      0.36      0.33      1536\n",
            "\n",
            "[[161 134  78   4   7   0]\n",
            " [ 70 172 132   4   6   0]\n",
            " [ 26  71 191  12   7   0]\n",
            " [ 28  47 124  13  18   0]\n",
            " [ 32  12  76  16  18   0]\n",
            " [ 13  11  35   4  14   0]]\n",
            "Epoch 1/8, Validation Loss: 1.5266, Validation Accuracy: 0.3613\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/8: 100%|██████████| 192/192 [06:44<00:00,  2.11s/batch, accuracy=0.363, loss=1.45]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.63      0.51       384\n",
            "           1       0.81      0.17      0.28       384\n",
            "           2       0.42      0.39      0.40       307\n",
            "           3       0.33      0.28      0.30       230\n",
            "           4       0.22      0.57      0.31       154\n",
            "           5       0.00      0.00      0.00        77\n",
            "\n",
            "    accuracy                           0.38      1536\n",
            "   macro avg       0.37      0.34      0.30      1536\n",
            "weighted avg       0.46      0.38      0.35      1536\n",
            "\n",
            "[[242  10  35  32  65   0]\n",
            " [145  64  79  29  67   0]\n",
            " [ 91   5 119  35  57   0]\n",
            " [ 53   0  44  65  68   0]\n",
            " [ 28   0   5  33  88   0]\n",
            " [  6   0   3   5  63   0]]\n",
            "Epoch 2/8, Validation Loss: 1.4068, Validation Accuracy: 0.3763\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/8: 100%|██████████| 192/192 [06:37<00:00,  2.07s/batch, accuracy=0.417, loss=1.38]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.39      0.49       384\n",
            "           1       0.60      0.41      0.49       384\n",
            "           2       0.41      0.61      0.49       307\n",
            "           3       0.38      0.45      0.41       230\n",
            "           4       0.29      0.56      0.38       154\n",
            "           5       0.29      0.03      0.05        77\n",
            "\n",
            "    accuracy                           0.45      1536\n",
            "   macro avg       0.44      0.41      0.38      1536\n",
            "weighted avg       0.50      0.45      0.44      1536\n",
            "\n",
            "[[151  64  77  48  44   0]\n",
            " [ 36 157 112  37  40   2]\n",
            " [ 12  22 188  50  34   1]\n",
            " [ 11   7  59 104  48   1]\n",
            " [ 11   6  19  30  87   1]\n",
            " [  9   4   5   7  50   2]]\n",
            "Epoch 3/8, Validation Loss: 1.3109, Validation Accuracy: 0.4486\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/8: 100%|██████████| 192/192 [06:59<00:00,  2.18s/batch, accuracy=0.437, loss=1.33]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.67      0.54       384\n",
            "           1       0.51      0.55      0.53       384\n",
            "           2       0.57      0.38      0.45       307\n",
            "           3       0.48      0.34      0.40       230\n",
            "           4       0.31      0.35      0.33       154\n",
            "           5       0.00      0.00      0.00        77\n",
            "\n",
            "    accuracy                           0.47      1536\n",
            "   macro avg       0.39      0.38      0.38      1536\n",
            "weighted avg       0.46      0.47      0.45      1536\n",
            "\n",
            "[[259  80  19  14  11   1]\n",
            " [103 213  39  10  18   1]\n",
            " [ 67  65 116  35  23   1]\n",
            " [ 72  20  28  78  32   0]\n",
            " [ 52  23   2  23  54   0]\n",
            " [ 24  14   1   4  34   0]]\n",
            "Epoch 4/8, Validation Loss: 1.2569, Validation Accuracy: 0.4688\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/8: 100%|██████████| 192/192 [06:57<00:00,  2.17s/batch, accuracy=0.461, loss=1.3]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.74      0.61       384\n",
            "           1       0.68      0.37      0.48       384\n",
            "           2       0.46      0.52      0.49       307\n",
            "           3       0.45      0.45      0.45       230\n",
            "           4       0.32      0.45      0.38       154\n",
            "           5       0.00      0.00      0.00        77\n",
            "\n",
            "    accuracy                           0.49      1536\n",
            "   macro avg       0.41      0.42      0.40      1536\n",
            "weighted avg       0.50      0.49      0.48      1536\n",
            "\n",
            "[[283  34  36  12  19   0]\n",
            " [ 97 143  91  24  29   0]\n",
            " [ 69  12 159  43  24   0]\n",
            " [ 46   6  37 103  38   0]\n",
            " [ 30   5  13  36  70   0]\n",
            " [ 16   9   6   9  37   0]]\n",
            "Epoch 5/8, Validation Loss: 1.2357, Validation Accuracy: 0.4935\n",
            "Best model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/8: 100%|██████████| 192/192 [06:43<00:00,  2.10s/batch, accuracy=0.487, loss=1.26]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.38      0.51       384\n",
            "           1       0.69      0.51      0.58       384\n",
            "           2       0.53      0.53      0.53       307\n",
            "           3       0.42      0.47      0.44       230\n",
            "           4       0.25      0.69      0.37       154\n",
            "           5       0.12      0.12      0.12        77\n",
            "\n",
            "    accuracy                           0.47      1536\n",
            "   macro avg       0.46      0.45      0.43      1536\n",
            "weighted avg       0.56      0.47      0.49      1536\n",
            "\n",
            "[[147  52  53  45  80   7]\n",
            " [ 23 194  65  32  46  24]\n",
            " [  6  17 162  56  51  15]\n",
            " [  9   5  19 109  84   4]\n",
            " [  6   6   6  17 106  13]\n",
            " [  1   8   0   1  58   9]]\n",
            "Epoch 6/8, Validation Loss: 1.3388, Validation Accuracy: 0.4733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/8: 100%|██████████| 192/192 [06:46<00:00,  2.12s/batch, accuracy=0.49, loss=1.22]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.70      0.54       384\n",
            "           1       0.51      0.58      0.54       384\n",
            "           2       0.48      0.23      0.31       307\n",
            "           3       0.42      0.33      0.37       230\n",
            "           4       0.40      0.38      0.39       154\n",
            "           5       0.31      0.05      0.09        77\n",
            "\n",
            "    accuracy                           0.46      1536\n",
            "   macro avg       0.43      0.38      0.37      1536\n",
            "weighted avg       0.45      0.46      0.43      1536\n",
            "\n",
            "[[268  78  14  18   6   0]\n",
            " [103 222  22  20  15   2]\n",
            " [ 72 101  71  47  14   2]\n",
            " [ 66  20  33  76  35   0]\n",
            " [ 63   7   5  15  59   5]\n",
            " [ 38   9   4   3  19   4]]\n",
            "Epoch 7/8, Validation Loss: 1.3688, Validation Accuracy: 0.4557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/8: 100%|██████████| 192/192 [06:54<00:00,  2.16s/batch, accuracy=0.515, loss=1.2]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61       384\n",
            "           1       0.60      0.60      0.60       384\n",
            "           2       0.48      0.57      0.52       307\n",
            "           3       0.47      0.50      0.49       230\n",
            "           4       0.36      0.36      0.36       154\n",
            "           5       0.26      0.13      0.17        77\n",
            "\n",
            "    accuracy                           0.53      1536\n",
            "   macro avg       0.47      0.46      0.46      1536\n",
            "weighted avg       0.52      0.53      0.52      1536\n",
            "\n",
            "[[223  80  40  29  10   2]\n",
            " [ 47 231  71  18  14   3]\n",
            " [ 21  49 174  41  20   2]\n",
            " [ 24   8  48 116  28   6]\n",
            " [ 23   7  17  36  55  16]\n",
            " [ 12  10  13   7  25  10]]\n",
            "Epoch 8/8, Validation Loss: 1.1596, Validation Accuracy: 0.5267\n",
            "Best model saved!\n",
            "Finished Training\n",
            "Best validation accuracy: 0.5267\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = TunnedBlockStackNet8()\n",
        "    trainer = ClassificationBlockStackTrainer1(\n",
        "        # csv_file = '/content/drive/MyDrive/CV final project/train data/train.csv', ##\n",
        "        # img_dir='/content/drive/MyDrive/CV final project/train data/train', ##\n",
        "        csv_file = './COMP90086_2024_Project_train/train.csv', ##\n",
        "        img_dir='./COMP90086_2024_Project_train/train', ##\n",
        "        model=model,\n",
        "        test_size=0.2, # used to control the size of data in split_dataset(self)\n",
        "        num_epochs=8,\n",
        "        #batch_size=32\n",
        "        )\n",
        "    trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
