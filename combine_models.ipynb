{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as datatime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadData(Dataset):\n",
    "\n",
    "  def __init__(self, df, img_dir,label_column, transform = None):\n",
    "    \"\"\"\n",
    "    Initialize the dataset\n",
    "    Args:\n",
    "      df: pandas dataframe, the data of the dataset\n",
    "      img_dir: string, the directory of the images\n",
    "      transform: torchvision.transforms, the transform to apply to the images\n",
    "    \"\"\"\n",
    "    self.df = df\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "    self.label_column = label_column\n",
    "    img_dir_path = Path(self.img_dir)\n",
    "\n",
    "    if not img_dir_path.exists():\n",
    "        raise ValueError(f\"The directory {img_dir_path} does not exist!\")\n",
    "    if not img_dir_path.is_dir() or not os.access(img_dir_path, os.R_OK):\n",
    "        raise ValueError(f\"The directory {img_dir_path} is not accessible or readable!\")\n",
    "      \n",
    "  \"\"\"\n",
    "  Get the length of data set\n",
    "  \"\"\"\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  \"\"\"\n",
    "  Get the image and label of the data set\n",
    "  Args:\n",
    "    index: int, the index of the image\n",
    "  Returns:  \n",
    "    image: PIL image, the image of the data set\n",
    "    label: int, the label of the data set\n",
    "  \"\"\"\n",
    "  def __getitem__(self, index):\n",
    "    img_name = os.path.join(self.img_dir, str(self.df.iloc[index, 0])) \n",
    "    image = Image.open(img_name + \".jpg\")\n",
    "\n",
    "    if self.label_column == 'instability_type':\n",
    "      label = self.df.iloc[index,4] \n",
    "  \n",
    "    elif self.label_column == 'stable_height': \n",
    "      label = self.df.iloc[index,-1] \n",
    "    \n",
    "    elif self.label_column == 'total_height':\n",
    "      label = self.df.iloc[index, 3]\n",
    "    else:\n",
    "      try:\n",
    "        print(self.label_column)\n",
    "      except:\n",
    "        print(\"Not found label column\")\n",
    "        \n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTunedGoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FineTunedGoogLeNet, self).__init__()\n",
    "        # load the pre-trained model: gogglenet\n",
    "        self.googlenet = models.googlenet(weights = models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        num_ftrs = self.googlenet.fc.in_features\n",
    "        self.googlenet.fc = nn.Identity()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128, 6)\n",
    "\n",
    "        )\n",
    "    def forward(self, x):\n",
    "      x = self.googlenet(x)\n",
    "      x = self.fc(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleFineTunedGoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleFineTunedGoogLeNet, self).__init__()\n",
    "\n",
    "        self.googlenet = models.googlenet(weights = models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        num_ftrs = self.googlenet.fc.in_features\n",
    "        self.googlenet.fc = nn.Identity()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.50),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "      x = self.googlenet(x)\n",
    "      x = self.fc(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './COMP90086_2024_Project_train/train.csv'\n",
    "img_dir = './COMP90086_2024_Project_train/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTemplate:\n",
    "    def __init__(self, model_path, model, label_column, \n",
    "                csv_path, img_dir, \n",
    "                stratify_column='stable_height', \n",
    "                test_size=0.2,\n",
    "                batch_size=32,\n",
    "                random_state = 42):\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.model = model\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.label_column = label_column\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.data_frame = pd.read_csv(csv_path)\n",
    "        self.stratify_column = stratify_column\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # preprocess images \n",
    "        self.transform = transforms.Compose([\n",
    "            # 这个变换将图像从PIL图像或NumPy数组转换为PyTorch张量。转换过程中，图像的像素值会被归一化到[0, 1]区间，\n",
    "            # 并且通道顺序会被调整为(C, H, W)，即通道数在前，高度和宽度在后。\n",
    "            transforms.ToTensor(),\n",
    "            # 这个变换对图像进行标准化。标准化操作是将图像的每个通道减去该通道的均值，然后除以该通道的标准差。\n",
    "            # 这里的均值和标准差是预训练的模型\n",
    "            # 在ImageNet数据集上计算得到的，用于确保图像的分布与模型训练时的分布一致，从而提高模型的泛化能力。\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "\n",
    "        # split data into train and validation \n",
    "        # Create data loader\n",
    "        self.train_data, self.val_data = self.split_train_valid()\n",
    "        self.train_loader = self.generate_dataloader(self.transform, self.train_data)\n",
    "        self.valid_loader = self.generate_dataloader(self.transform, self.val_data,  shuffle=False)\n",
    "        \n",
    "        self.model = self.load_model()\n",
    "\n",
    "\n",
    "    def split_train_valid(self):\n",
    "        train_data, val_data = train_test_split(\n",
    "                                    self.data_frame,\n",
    "                                    test_size=self.test_size,\n",
    "                                    random_state=self.random_state,\n",
    "                                    stratify=self.data_frame[self.stratify_column]\n",
    "                                )\n",
    "\n",
    "        print(f\"Train dataset size: {len(train_data)}\",\n",
    "                f\"Validation dataset size: {len(val_data)}\")\n",
    "        return train_data, val_data\n",
    "\n",
    "\n",
    "    def load_model(self):\n",
    "      #  self.model.load_state_dict(torch.load(self.model_path, map_location=self.device,weights_only=True))\n",
    "        self.model.load_state_dict(torch.load(self.model_path, map_location=self.device,weights_only=True))\n",
    "\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def generate_dataloader(self, transform, data_frame, shuffle=True):\n",
    "      #  print(\"label column type\", self.label_column)\n",
    "        dataset = ReadData(data_frame, self.img_dir,self.label_column, transform=transform) \n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "\n",
    "    def generate_classification_report(self, outputs, labels):\n",
    "        matrix = confusion_matrix(labels, outputs)\n",
    "        print(classification_report(labels, outputs, zero_division=0))\n",
    "        print(matrix)\n",
    "\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        num_cor_pred = 0\n",
    "        num_samples = 0\n",
    "        gt_labels = []\n",
    "        pred_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device).long()\n",
    "                outputs = self.model(inputs)\n",
    "                pred_class = torch.argmax(outputs, 1)\n",
    "                if self.label_column == 'stable_height' or self.label_column == 'total_height':\n",
    "                    pred_class = pred_class + 1\n",
    "          #      labels = labels - 1\n",
    "\n",
    "                gt_labels.extend(labels.cpu().numpy())\n",
    "                pred_labels.extend(pred_class.cpu().numpy())\n",
    "                # calculate number of correct predictions\n",
    "                num_cor_pred += (pred_class == labels).sum().item()\n",
    "                num_samples += labels.size(0)\n",
    "\n",
    "        # calculate the accuracy rate\n",
    "        val_accuracy = num_cor_pred / num_samples\n",
    "        self.generate_classification_report(np.array(pred_labels), np.array(gt_labels))\n",
    "        self.pred_labels = pred_labels\n",
    "        return val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: directly predict the stable height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 6144 Validation dataset size: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_66405/4194297799.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.model_path, map_location=self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       384\n",
      "           2       0.73      0.72      0.72       384\n",
      "           3       0.64      0.70      0.67       307\n",
      "           4       0.59      0.66      0.62       230\n",
      "           5       0.62      0.55      0.59       154\n",
      "           6       0.54      0.34      0.42        77\n",
      "\n",
      "    accuracy                           0.67      1536\n",
      "   macro avg       0.64      0.62      0.62      1536\n",
      "weighted avg       0.67      0.67      0.67      1536\n",
      "\n",
      "[[278  37  29  27  10   3]\n",
      " [ 38 278  30  24   9   5]\n",
      " [ 25  40 215  18   4   5]\n",
      " [ 18  11  33 151  13   4]\n",
      " [  8   7  18  31  85   5]\n",
      " [ 10  10  13   3  15  26]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6725260416666666"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valider_stabHei = ModelTemplate(\n",
    "    model_path = './runs/20241012-StableHeight-BestModel-net8-acc0666/best_model.pth',\n",
    "    model=FineTunedGoogLeNet(),\n",
    "    label_column = 'stable_height',\n",
    "    csv_path = csv_path, img_dir= img_dir, \n",
    "    test_size=0.2,\n",
    "    batch_size=32\n",
    "    )\n",
    "valider_stabHei.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_label\n",
       "2    383\n",
       "1    377\n",
       "3    338\n",
       "4    254\n",
       "5    136\n",
       "6     48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = valider_stabHei.val_data\n",
    "all_pred = valider_stabHei.pred_labels\n",
    "valid_df['pred_label'] = all_pred\n",
    "valid_df['pred_type'] = valid_df['pred_label'] == valid_df['stable_height']\n",
    "valid_df.pred_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 6144 Validation dataset size: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_66405/21067871.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.model_path, map_location=self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.72      0.73       384\n",
      "           2       0.73      0.72      0.72       384\n",
      "           3       0.64      0.70      0.67       307\n",
      "           4       0.59      0.66      0.62       230\n",
      "           5       0.62      0.55      0.59       154\n",
      "           6       0.54      0.34      0.42        77\n",
      "\n",
      "    accuracy                           0.67      1536\n",
      "   macro avg       0.64      0.62      0.62      1536\n",
      "weighted avg       0.67      0.67      0.67      1536\n",
      "\n",
      "[[278  37  29  27  10   3]\n",
      " [ 38 278  30  24   9   5]\n",
      " [ 25  40 215  18   4   5]\n",
      " [ 18  11  33 151  13   4]\n",
      " [  8   7  18  31  85   5]\n",
      " [ 10  10  13   3  15  26]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = FineTunedGoogLeNet()\n",
    "    valider = ModelTemplate(\n",
    "        model_path = './runs/20241012-StableHeight-BestModel-net8-acc0666/best_model.pth',\n",
    "        model=model,\n",
    "        label_column = 'stable_height',\n",
    "        csv_file = './COMP90086_2024_Project_train/train.csv', ##\n",
    "        img_dir='./COMP90086_2024_Project_train/train', ##\n",
    "        test_size=0.2, # used to control the size of data in split_dataset(self)\n",
    "        batch_size=32\n",
    "        )\n",
    "    valider.validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = valider.val_data\n",
    "pred_labels = valider.pred_labels\n",
    "valid_df['pred_label'] = pred_labels\n",
    "valid_df['pred_type'] = valid_df['pred_label'] == valid_df['stable_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shapeset</th>\n",
       "      <th>type</th>\n",
       "      <th>total_height</th>\n",
       "      <th>instability_type</th>\n",
       "      <th>cam_angle</th>\n",
       "      <th>stable_height</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>956915</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>516709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>77447</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>212770</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>745098</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
       "7334  956915         2     2             4                 2          1   \n",
       "3955  516709         1     2             5                 1          1   \n",
       "619    77447         1     2             5                 1          1   \n",
       "1594  212770         2     2             4                 2          1   \n",
       "5645  745098         2     2             6                 1          1   \n",
       "\n",
       "      stable_height  pred_label  pred_type  \n",
       "7334              1           1       True  \n",
       "3955              3           2      False  \n",
       "619               3           3       True  \n",
       "1594              1           1       True  \n",
       "5645              4           2      False  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instability_type  type\n",
       "0                 1       0.784431\n",
       "                  2       0.376238\n",
       "1                 1       0.733333\n",
       "                  2       0.454780\n",
       "2                 1       0.932039\n",
       "                  2       0.934783\n",
       "Name: pred_type, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.groupby(['instability_type', 'type']).pred_type.sum()/valid_df.groupby(['instability_type', 'type']).pred_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instability_type  type  cam_angle\n",
       "0                 1     1            116\n",
       "                        2             51\n",
       "                  2     1            150\n",
       "                        2             52\n",
       "1                 1     1            291\n",
       "                        2             99\n",
       "                  2     1            295\n",
       "                        2             92\n",
       "2                 1     1            161\n",
       "                        2             45\n",
       "                  2     1            141\n",
       "                        2             43\n",
       "Name: pred_type, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.groupby(['instability_type', 'type','cam_angle']).pred_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instability_type  type  cam_angle\n",
       "0                 1     1            0.853448\n",
       "                        2            0.627451\n",
       "                  2     1            0.380000\n",
       "                        2            0.365385\n",
       "1                 1     1            0.745704\n",
       "                        2            0.696970\n",
       "                  2     1            0.477966\n",
       "                        2            0.380435\n",
       "2                 1     1            0.987578\n",
       "                        2            0.733333\n",
       "                  2     1            0.964539\n",
       "                        2            0.837209\n",
       "Name: pred_type, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.groupby(['instability_type', 'type','cam_angle']).pred_type.sum()/valid_df.groupby(['instability_type', 'type','cam_angle']).pred_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instability_type  shapeset\n",
       "0                 1           0.530435\n",
       "                  2           0.574803\n",
       "1                 1           0.687351\n",
       "                  2           0.486034\n",
       "2                 2           0.933333\n",
       "Name: pred_type, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.groupby(['instability_type','shapeset']).pred_type.sum()/valid_df.groupby(['instability_type','shapeset']).pred_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shapeset  type\n",
       "1         1       0.860465\n",
       "          2       0.460145\n",
       "2         1       0.766337\n",
       "          2       0.597586\n",
       "Name: pred_type, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.groupby(['shapeset','type']).pred_type.sum()/valid_df.groupby(['shapeset','type']).pred_type.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shapeset</th>\n",
       "      <th>type</th>\n",
       "      <th>total_height</th>\n",
       "      <th>instability_type</th>\n",
       "      <th>cam_angle</th>\n",
       "      <th>stable_height</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>231667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>626871</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>357993</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>852975</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>711689</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>380572</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>206872</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>279373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>893651</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>785888</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
       "1745  231667         2     2             6                 0          1   \n",
       "4744  626871         2     2             5                 0          1   \n",
       "2714  357993         2     2             3                 0          1   \n",
       "6493  852975         2     2             5                 0          1   \n",
       "5391  711689         2     2             2                 0          2   \n",
       "...      ...       ...   ...           ...               ...        ...   \n",
       "2878  380572         2     2             2                 0          1   \n",
       "1547  206872         2     2             2                 0          2   \n",
       "2096  279373         2     2             5                 0          1   \n",
       "6836  893651         2     2             3                 0          1   \n",
       "5966  785888         2     2             5                 0          1   \n",
       "\n",
       "      stable_height  pred_label  pred_type  \n",
       "1745              6           5      False  \n",
       "4744              5           3      False  \n",
       "2714              3           1      False  \n",
       "6493              5           1      False  \n",
       "5391              2           1      False  \n",
       "...             ...         ...        ...  \n",
       "2878              2           1      False  \n",
       "1547              2           1      False  \n",
       "2096              5           4      False  \n",
       "6836              3           2      False  \n",
       "5966              5           4      False  \n",
       "\n",
       "[78 rows x 9 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df[(valid_df['type']==2)&(valid_df['pred_type']==False)&(valid_df['instability_type']==0)&(valid_df['shapeset']==2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Predict the instability type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 6144 Validation dataset size: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/b497571d49ndglvgyk5sb53h0000gn/T/ipykernel_86745/2085106257.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.model_path, map_location=self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.22      0.31       369\n",
      "           1       0.70      0.88      0.78       777\n",
      "           2       0.91      0.95      0.93       390\n",
      "\n",
      "    accuracy                           0.74      1536\n",
      "   macro avg       0.72      0.68      0.68      1536\n",
      "weighted avg       0.72      0.74      0.71      1536\n",
      "\n",
      "[[ 82 273  14]\n",
      " [ 68 687  22]\n",
      " [  2  19 369]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7408854166666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valider_instabType = ModelTemplate(\n",
    "    model_path = './runs/20241013-Class-InstabilityType-ClassWeight114/best_model.pth',\n",
    "    model= SimpleFineTunedGoogLeNet(),\n",
    "    label_column = 'instability_type',\n",
    "    csv_path = csv_path, img_dir= img_dir, \n",
    "    test_size=0.2,\n",
    "    batch_size=32\n",
    "    )\n",
    "valider_instabType.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewer layers in fine tuned googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 6144 Validation dataset size: 1536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.43      0.50       369\n",
      "           1       0.75      0.88      0.81       777\n",
      "           2       0.98      0.92      0.95       390\n",
      "\n",
      "    accuracy                           0.78      1536\n",
      "   macro avg       0.78      0.74      0.75      1536\n",
      "weighted avg       0.77      0.78      0.77      1536\n",
      "\n",
      "[[157 207   5]\n",
      " [ 92 681   4]\n",
      " [  8  22 360]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7799479166666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valider_instabType = ModelTemplate(\n",
    "    model_path = './runs/20241013-Class-InstabilityType-net8/best_model.pth',\n",
    "    model= FineTunedGoogLeNet(),\n",
    "    label_column = 'instability_type',\n",
    "    csv_path = csv_path, img_dir= img_dir, \n",
    "    test_size=0.2,\n",
    "    batch_size=32\n",
    "    )\n",
    "valider_instabType.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 6144 Validation dataset size: 1536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.95      1.00      0.97       149\n",
      "           3       0.93      0.96      0.95       222\n",
      "           4       0.92      0.95      0.94       304\n",
      "           5       0.94      0.91      0.92       395\n",
      "           6       0.98      0.94      0.96       466\n",
      "\n",
      "    accuracy                           0.95      1536\n",
      "   macro avg       0.94      0.95      0.95      1536\n",
      "weighted avg       0.95      0.95      0.95      1536\n",
      "\n",
      "[[149   0   0   0   0]\n",
      " [  8 213   1   0   0]\n",
      " [  0  14 290   0   0]\n",
      " [  0   1  24 360  10]\n",
      " [  0   0   1  25 440]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9453125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valider_tt_height = ModelTemplate(\n",
    "    model_path = './runs/20241014-TotalHeight-Classification-net8/best_model.pth',\n",
    "    model=FineTunedGoogLeNet(),\n",
    "    label_column = 'total_height',\n",
    "    csv_path = csv_path, img_dir= img_dir, \n",
    "    test_size=0.2,\n",
    "    batch_size=32\n",
    "    )\n",
    "valider_tt_height.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shapeset</th>\n",
       "      <th>type</th>\n",
       "      <th>total_height</th>\n",
       "      <th>instability_type</th>\n",
       "      <th>cam_angle</th>\n",
       "      <th>stable_height</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>956915</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>516709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>77447</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>212770</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>745098</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  shapeset  type  total_height  instability_type  cam_angle  \\\n",
       "7334  956915         2     2             4                 2          1   \n",
       "3955  516709         1     2             5                 1          1   \n",
       "619    77447         1     2             5                 1          1   \n",
       "1594  212770         2     2             4                 2          1   \n",
       "5645  745098         2     2             6                 1          1   \n",
       "\n",
       "      stable_height  pred_label  pred_type  \n",
       "7334              1           4       True  \n",
       "3955              3           5       True  \n",
       "619               3           5       True  \n",
       "1594              1           4       True  \n",
       "5645              4           6       True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_df = valider_tt_height.val_data\n",
    "pred_labels = valider_tt_height.pred_labels\n",
    "tt_df['pred_label'] = pred_labels\n",
    "tt_df['pred_type'] = tt_df['pred_label'] == tt_df['total_height']\n",
    "tt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71,  0,  0,  0,  0],\n",
       "       [ 4, 79,  1,  0,  0],\n",
       "       [ 0,  5, 65,  0,  0],\n",
       "       [ 0,  0,  3, 61,  3],\n",
       "       [ 0,  0,  0,  2, 75]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_type_gt = tt_df[tt_df['instability_type']==0].total_height.tolist()\n",
    "stable_type_pred = tt_df[tt_df['instability_type']==0].pred_label.tolist()\n",
    "confusion_matrix(stable_type_gt, stable_type_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "  '''\n",
    "  get the image and the file path\n",
    "  '''\n",
    "  def __init__(self, csv_file, img_dir, transform = None):\n",
    "    self.data_frame = pd.read_csv(csv_file)\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "\n",
    "  '''\n",
    "  Return the size of the dataset\n",
    "  '''\n",
    "  def __len__(self):\n",
    "    return len(self.data_frame)\n",
    "\n",
    "  '''\n",
    "  get the image and related column\n",
    "  '''\n",
    "  def __getitem__(self, idx):\n",
    "    img_name = os.path.join(self.img_dir, str(self.data_frame.iloc[idx, 0]))\n",
    "    image = Image.open(img_name + \".jpg\")\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image, self.data_frame.iloc[idx, 0]\n",
    "\n",
    "\n",
    "\n",
    "class BlockStackPredictor:\n",
    "    def __init__(self, model, model_path, test_csv, img_dir, batch_size=32):\n",
    "        self.model = model\n",
    "        self.model_path = model_path\n",
    "        self.test_csv = test_csv\n",
    "        self.img_dir = img_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # 设备配置\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 加载模型权重\n",
    "        #self.model = self.load_model(self.model, self.model_path)\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        # 图像转换操作\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # 创建 DataLoader\n",
    "        self.test_loader = self.create_dataloader()\n",
    "\n",
    "    #改\n",
    "    def load_model(self):\n",
    "        \"\"\"加载训练好的模型权重。\n",
    "\n",
    "        参数:\n",
    "        model (nn.Module): 要加载权重的模型。\n",
    "        model_path (str): 模型权重文件的路径。\n",
    "\n",
    "        返回:\n",
    "        model (nn.Module): 加载了权重的模型。\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(torch.load(self.model_path, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        return model\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        test_dataset = TestDataset(self.test_csv, self.img_dir, transform=self.transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        return test_loader\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        all_predictions = []\n",
    "        all_image_ids = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, image_ids in tqdm(self.test_loader, desc=\"testing\"):\n",
    "                images = images.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                #outputs = torch.round(outputs).clamp(1,6) #在1-6之间输出\n",
    "                predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                #predictions = outputs.squeeze().cpu().numpy()\n",
    "                predictions = predictions.astype(int) + 1\n",
    "                #predictions = predictions.astype(int)\n",
    "\n",
    "                all_predictions.extend(predictions)\n",
    "                all_image_ids.extend(image_ids.numpy())\n",
    "\n",
    "\n",
    "        prediction_df = pd.DataFrame({\n",
    "            'id': all_image_ids,\n",
    "            'stable_height': all_predictions\n",
    "             })\n",
    "\n",
    "        return prediction_df\n",
    "\n",
    "    def save_predictions(self, output_csv):\n",
    "      \"\"\"将预测结果保存为CSV文件。\"\"\"\n",
    "      prediction_df = self.predict()\n",
    "      prediction_df.to_csv(output_csv, index=False)\n",
    "      print(f\"预测结果已保存到 {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the model object from a defined class BlockStackNet7\n",
    "    model = TunnedBlockStackNet11()\n",
    "\n",
    "    # Path to the trained model's weights\n",
    "    model_path = 'Physical_Reasoning/runs/20241012-StableHeight-BestModel-net8-acc0666/best_model.pth' # BLOCK10,reg-CrossEntropy(128,6)-start-512-epoch-30 validation-loss:0.652 test:\n",
    "    # Directory where test images are stored\n",
    "    img_dir = '/content/drive/MyDrive/CV final project/test data/test'\n",
    "\n",
    "    # Create a predictor instance with the specified model, model path, test data csv file, and image directory\n",
    "    predictor = BlockStackPredictor(\n",
    "        model=model,\n",
    "        model_path=model_path,\n",
    "        test_csv=test_csv,\n",
    "        img_dir=img_dir,\n",
    "        batch_size=32  # Specifying the batch size for processing\n",
    "    )\n",
    "\n",
    "    # Use the predictor to generate predictions\n",
    "    prediction_df = predictor.predict()\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    predictor.save_predictions('/content/drive/MyDrive/CV final project/BLOCK11-reg-CrossEntropy-30epoches-start256-128-6-034836.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
